{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3af3927",
   "metadata": {},
   "source": [
    "# Workshop week 6: Deep Learning and Reinforcement Learning\n",
    "\n",
    "## 1. MNIST dataset classification using CNN\n",
    "\n",
    "In Week 11 you learned that Convolutional Neural Network (CNN) is a neural network architecture used to classify images. <br>\n",
    "In this activity, you will learn how to apply CNN to recognise hand-written digits to classify them into 0-9 digits.<br>\n",
    "This is a simple version of a much larger application that converts handwriting into computer recognised text.\n",
    "\n",
    "Before starting this task, please refresh your knowledge from Week 11 Online Learning and lecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cf0bb3",
   "metadata": {},
   "source": [
    "### Activity 1: Creating CNN for image classification\n",
    "\n",
    "In this activity, you will create a configuration of CNN as specfied. Please complete the code in the indicated places. You can work in groups and consult each other on how to do it efficiently. Keras APIs documentation can be found here: https://keras.io/api/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b047b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and plot the first 9 digints\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(trainX[i], cmap=plt.get_cmap('gray'))\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048adc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline cnn model for mnist\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd415bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "    \n",
    "    # reshape dataset to have a single channel\n",
    "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "    \n",
    "    # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    \n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    \n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    \n",
    "    # return normalized images\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae13c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "    define \n",
    "    convolution 2D layer with:\n",
    "        32 filters\n",
    "        3x3 filter size\n",
    "        relu activation\n",
    "        default stride\n",
    "        Make sure the input_shape follows actual data shape you are going to fit  \n",
    "    pooling layer with 2x2 size and default stride\n",
    "    flatten the image before it goes to fully connected NN\n",
    "    2 fully connected NN: \n",
    "        one with 100 neurons and relu activation\n",
    "        second one with 10 neurons and softmax activation\n",
    "    compile the model with \n",
    "        SGD optimiser with\n",
    "            learnign rate = 0.01 \n",
    "            momentum = 0.9, \n",
    "        categorical cross-entropy loss function\n",
    "        accuracy metric\n",
    "\"\"\"\"\n",
    "\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    # your code here\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "    scores, histories = list(), list()\n",
    "    # prepare cross validation\n",
    "    kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(dataX):\n",
    "        # define model\n",
    "        model = define_model()\n",
    "        # select rows for train and test\n",
    "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "        # fit model\n",
    "        history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "        # evaluate model\n",
    "        _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "        print('> %.3f' % (acc * 100.0))\n",
    "        # stores scores\n",
    "        scores.append(acc)\n",
    "        histories.append(history)\n",
    "    return scores, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce2b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.title('Cross Entropy Loss')\n",
    "        plt.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "        plt.plot(histories[i].history['val_loss'], color='green', label='test')\n",
    "        # plot accuracy\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
    "        plt.plot(histories[i].history['val_accuracy'], color='green', label='test')\n",
    "        plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852be55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "# load dataset\n",
    "trainX, trainY, testX, testY = load_dataset()\n",
    "# prepare pixel data\n",
    "trainX, testX = prep_pixels(trainX, testX)\n",
    "# evaluate model\n",
    "scores, histories = evaluate_model(trainX, trainY)\n",
    "# learning curves\n",
    "summarize_diagnostics(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44465995",
   "metadata": {},
   "source": [
    "### Activity 2: Discuss the results\n",
    "\n",
    "Analyse the output charts and answer the following questions:\n",
    "1. What would be the number of epochs sufficient to obtain good classification results?\n",
    "2. What CNN parameters would you change to improve results?\n",
    "\n",
    "Your workshop instructor may have some more questions to discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc497bc0",
   "metadata": {},
   "source": [
    "## 2. Reinforcement Learning\n",
    "\n",
    "Reinforcement learning (RL) is a subset of machine learning that allows an AI-driven system (sometimes referred to as an agent) to learn through trial and error using feedback from its actions.\n",
    "\n",
    "One example is Q-Learning. Q-learning is a machine learning approach that enables a model to iteratively learn and improve over time by taking the correct action. \n",
    "\n",
    "### Activity 3: Read the following article and answer the below questions. \n",
    "\n",
    "Article: https://www.techtarget.com/searchenterpriseai/definition/Q-learning\n",
    "\n",
    "\n",
    "1. Describe the components involved in reinforcement learning, such as agents, states, actions, rewards, episodes, and Q-values.\n",
    "2. How does the off-policy approach work in Q-learning, and what role do Q-values play in achieving this approach?\n",
    "3. What is a Q-table, and how is it utilized in reinforcement learning?\n",
    "4. Explain the relationship between the Q-table and the Q-function in the context of reinforcement learning.\n",
    "5. What are the advantages of using a Q-learning approach in reinforcement learning?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
